{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodeGen_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODWUN5pMLEoKfo3Nyt2aHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghav-menon/END/blob/main/Session14/CodeGen_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePVDJ5mb_DyY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.legacy.data import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "from tokenize import tokenize\n",
        "from io import BytesIO\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from google.colab import drive\n",
        "import os\n",
        "from torchtext.legacy.data import Example"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZAWfI6Ts_GGJ",
        "outputId": "d78416e4-ed47-493d-9d68-44d64be6dca8"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7I3-b0t_PDU",
        "outputId": "510a601b-9c37-4686-fa2e-b29cd66f87b0"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2ylA_zU_ztc",
        "outputId": "49c1d9c8-10dc-4059-9035-85285036a518"
      },
      "source": [
        "os.chdir('gdrive/MyDrive/End_Capstone')\n",
        "os.listdir('.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['conala-corpus',\n",
              " 'Conala.zip',\n",
              " 'english_python_data.txt',\n",
              " 'english_python_data_v1.txt',\n",
              " '.ipynb_checkpoints',\n",
              " 'tut6-model.pt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdg5SJs9I29n"
      },
      "source": [
        "# Getting the CoNaLa corpus\n",
        "#!wget -O Conala.zip \"http://www.phontron.com/download/conala-corpus-v1.1.zip\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMmKogxbLWmM"
      },
      "source": [
        "# Unzipping CoNaLa corpus\n",
        "#!unzip -n Conala.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZVvagNFL8oT",
        "outputId": "44f9ca8e-4425-465e-8883-e8a1540122dd"
      },
      "source": [
        "!head conala-corpus/conala-train.json"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"intent\": \"How to convert a list of multiple integers into a single integer?\",\n",
            "    \"rewritten_intent\": \"Concatenate elements of a list 'x' of multiple integers to a single integer\",\n",
            "    \"snippet\": \"sum(d * 10 ** i for i, d in enumerate(x[::-1]))\",\n",
            "    \"question_id\": 41067960\n",
            "  },\n",
            "  {\n",
            "    \"intent\": \"How to convert a list of multiple integers into a single integer?\",\n",
            "    \"rewritten_intent\": \"convert a list of integers into a single integer\",\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjj1SolpMS9L"
      },
      "source": [
        "questions, answers = [],[]\n",
        "\n",
        "# loading train json\n",
        "import json\n",
        "f = open(\"conala-corpus/conala-train.json\",\"r\")\n",
        "train_file = json.load(f)\n",
        "f.close()\n",
        "\n",
        "for num,intent in enumerate(train_file):\n",
        "  if intent['intent'] is not None:\n",
        "    questions.append(intent['intent'])\n",
        "    answers.append(intent['snippet'])\n",
        "  if intent['rewritten_intent'] is not None:\n",
        "    questions.append(intent['rewritten_intent'])\n",
        "    answers.append(intent['snippet'])\n",
        "\n",
        "# loading train json\n",
        "f = open(\"conala-corpus/conala-test.json\",\"r\")\n",
        "test_file = json.load(f)\n",
        "f.close()\n",
        "\n",
        "for num,intent in enumerate(test_file):\n",
        "  if intent['intent'] is not None:\n",
        "    questions.append(intent['intent'])\n",
        "    answers.append(intent['snippet'])\n",
        "  if intent['rewritten_intent'] is not None:\n",
        "    questions.append(intent['rewritten_intent'])\n",
        "    answers.append(intent['snippet'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS_LaXkANfrA",
        "outputId": "acbc0932-8ba0-441b-a310-d363358ee238"
      },
      "source": [
        "questions[:10], answers[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['How to convert a list of multiple integers into a single integer?',\n",
              "  \"Concatenate elements of a list 'x' of multiple integers to a single integer\",\n",
              "  'How to convert a list of multiple integers into a single integer?',\n",
              "  'convert a list of integers into a single integer',\n",
              "  'how to convert a datetime string back to datetime object?',\n",
              "  \"convert a DateTime string back to a DateTime object of format '%Y-%m-%d %H:%M:%S.%f'\",\n",
              "  'Averaging the values in a dictionary based on the key',\n",
              "  'get the average of a list values for each key in dictionary `d`)',\n",
              "  'zip lists in python',\n",
              "  'zip two lists `[1, 2]` and `[3, 4]` into a list of two tuples containing elements at the same index in each list'],\n",
              " ['sum(d * 10 ** i for i, d in enumerate(x[::-1]))',\n",
              "  'sum(d * 10 ** i for i, d in enumerate(x[::-1]))',\n",
              "  \"r = int(''.join(map(str, x)))\",\n",
              "  \"r = int(''.join(map(str, x)))\",\n",
              "  \"datetime.strptime('2010-11-13 10:33:54.227806', '%Y-%m-%d %H:%M:%S.%f')\",\n",
              "  \"datetime.strptime('2010-11-13 10:33:54.227806', '%Y-%m-%d %H:%M:%S.%f')\",\n",
              "  '[(i, sum(j) / len(j)) for i, j in list(d.items())]',\n",
              "  '[(i, sum(j) / len(j)) for i, j in list(d.items())]',\n",
              "  'zip([1, 2], [3, 4])',\n",
              "  'zip([1, 2], [3, 4])'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up0tvlKqP_c6",
        "outputId": "65b67dee-5696-42fd-c0be-03533e2d1073"
      },
      "source": [
        "len(questions), len(answers)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5656, 5656)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlaATFU6_9RU"
      },
      "source": [
        "# Reading Code question and the python code from the provided file\n",
        "qlist = []\n",
        "alist = []\n",
        "with open(os.path.join(\"\", \"english_python_data_v1.txt\"), \"r\") as f:\n",
        "  data = f.readlines()\n",
        "line = False\n",
        "for QCode in data:\n",
        "  if QCode.startswith(\"#$$$\"):\n",
        "    temp = ' '.join(Q for Q in QCode.split()[1:])\n",
        "    qlist.append(temp)\n",
        "    if line == False:\n",
        "      Alist = []\n",
        "      line  = True\n",
        "    else:\n",
        "      alist.append(''.join(ans for ans in Alist))\n",
        "      Alist = []\n",
        "  else:\n",
        "    Alist.append(QCode)\n",
        "alist.append(''.join(ans for ans in Alist))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYZqk7yi7GZP",
        "outputId": "f3f7abee-6e9e-49ec-89ea-3c9193b0e4a7"
      },
      "source": [
        "print(len(qlist), len(alist))\n",
        "qlist.extend(questions)\n",
        "alist.extend(answers)\n",
        "print(len(qlist), len(alist))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4324 4324\n",
            "9980 9980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4fqhIZWAGrw"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LED34JoDAMDw"
      },
      "source": [
        "def tokenize_en(text):\n",
        "  \"\"\"\n",
        "  Tokenizes English text from a string into a list of strings\n",
        "  \"\"\"\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def codetokenize(text):\n",
        " # \"\"\"\n",
        "  #Tokenizes the python code \n",
        "  #\"\"\"\n",
        "  tokens = []\n",
        "  a = list(tokenize(BytesIO(text.encode('utf-8')).readline))\n",
        "  for i__ in a[1:-1]:\n",
        "      if i__.exact_type == 3:\n",
        "          string_tokens = [k__ for k__ in i__[1]]\n",
        "          tokens = tokens + string_tokens\n",
        "      elif i__.exact_type == 6:   \n",
        "          continue\n",
        "      else:\n",
        "          tokens.append(i__[1])\n",
        "  return tokens"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIo7OfJt7o0p",
        "outputId": "efa611cc-950f-4797-8936-cee0c597de65"
      },
      "source": [
        "LLL = []\n",
        "for l in range(0,len(alist)):\n",
        "  try:\n",
        "    d = codetokenize(alist[l])\n",
        "  except: \n",
        "    LLL.append(l)\n",
        "    continue\n",
        "print(LLL)\n",
        "\n",
        "#print(d)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ctZtzk0T9v9f",
        "outputId": "d3438da6-56ca-4477-d8ce-b1b341f7c125"
      },
      "source": [
        "alist[9000]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"c.execute('SELECT * FROM foo WHERE bar = %s AND baz = %s', (param1, param2))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxhOefImCW6_"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = codetokenize,       #tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = False, \n",
        "            batch_first = True)\n",
        "\n",
        "fields = [('src', SRC), ('trg', TRG)]\n",
        "Gensample = [Example.fromlist([qlist[k], alist[k]], fields) for k in range(len(qlist))] \n",
        "dataset = Dataset(Gensample, fields=fields)\n",
        "#Tdata, test_data = dataset.split(0.9)\n",
        "#train_data, valid_data = Tdata.split(0.8)\n",
        "train_data, valid_data = dataset.split(0.8)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2bwTYx4byrm"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 20)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugf5teIyLO5G",
        "outputId": "b2e4fee7-e14c-477f-8b22-af26ff65ed90"
      },
      "source": [
        "len(SRC.vocab), len(TRG.vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2357, 529)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbnnxZ7icyKD",
        "outputId": "a1de5ed2-d061-485d-b180-556fcc054a1e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z60AQbfgc2uE"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "#train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        " #   (train_data, valid_data, test_data), \n",
        "  #   batch_size = BATCH_SIZE,\n",
        "   #  sort_key = lambda x: len(x.trg),\n",
        "    # device = device)\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key = lambda x: len(x.trg),\n",
        "     device = device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eedWM3auc7qy"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40gXYwLNdDxX"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK7PmF5GdLpu"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w5S_WMUe3Bm"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thBv96GHdR60"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eHgSPedddzv"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CopYiafxdf3b"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysWBNwgLdxF4"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 2\n",
        "DEC_LAYERS = 4\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.15\n",
        "DEC_DROPOUT = 0.15\n",
        "max_length = 3000\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device,\n",
        "              max_length)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmyihDvvfKrA"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOVK_APYfUrT",
        "outputId": "654e2be4-6ec1-4805-ee04-90b417f9e5ea"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,885,713 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCxkSRTIfcCT"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyGfxr1OfgR7"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-WQ5nodfkQD"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVurLIj_fpNz"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzPfhVGNfx7e"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL34jZxaf0Al"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feXkC6EEf5GS"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhbNhvb1f-2X",
        "outputId": "424e30e9-6e90-4882-9990-71e1aac5e0bf"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6m-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 33s\n",
            "\tTrain Loss: 3.254 | Train PPL:  25.898\n",
            "\t Val. Loss: 2.341 |  Val. PPL:  10.388\n",
            "Epoch: 02 | Time: 0m 33s\n",
            "\tTrain Loss: 2.412 | Train PPL:  11.158\n",
            "\t Val. Loss: 1.997 |  Val. PPL:   7.367\n",
            "Epoch: 03 | Time: 0m 34s\n",
            "\tTrain Loss: 2.145 | Train PPL:   8.542\n",
            "\t Val. Loss: 1.798 |  Val. PPL:   6.036\n",
            "Epoch: 04 | Time: 0m 34s\n",
            "\tTrain Loss: 1.968 | Train PPL:   7.156\n",
            "\t Val. Loss: 1.681 |  Val. PPL:   5.373\n",
            "Epoch: 05 | Time: 0m 33s\n",
            "\tTrain Loss: 1.825 | Train PPL:   6.205\n",
            "\t Val. Loss: 1.588 |  Val. PPL:   4.893\n",
            "Epoch: 06 | Time: 0m 33s\n",
            "\tTrain Loss: 1.710 | Train PPL:   5.526\n",
            "\t Val. Loss: 1.514 |  Val. PPL:   4.543\n",
            "Epoch: 07 | Time: 0m 33s\n",
            "\tTrain Loss: 1.620 | Train PPL:   5.055\n",
            "\t Val. Loss: 1.472 |  Val. PPL:   4.356\n",
            "Epoch: 08 | Time: 0m 33s\n",
            "\tTrain Loss: 1.542 | Train PPL:   4.673\n",
            "\t Val. Loss: 1.405 |  Val. PPL:   4.075\n",
            "Epoch: 09 | Time: 0m 33s\n",
            "\tTrain Loss: 1.465 | Train PPL:   4.327\n",
            "\t Val. Loss: 1.374 |  Val. PPL:   3.950\n",
            "Epoch: 10 | Time: 0m 33s\n",
            "\tTrain Loss: 1.402 | Train PPL:   4.063\n",
            "\t Val. Loss: 1.354 |  Val. PPL:   3.872\n",
            "Epoch: 11 | Time: 0m 34s\n",
            "\tTrain Loss: 1.346 | Train PPL:   3.843\n",
            "\t Val. Loss: 1.315 |  Val. PPL:   3.725\n",
            "Epoch: 12 | Time: 0m 34s\n",
            "\tTrain Loss: 1.287 | Train PPL:   3.624\n",
            "\t Val. Loss: 1.301 |  Val. PPL:   3.672\n",
            "Epoch: 13 | Time: 0m 33s\n",
            "\tTrain Loss: 1.237 | Train PPL:   3.446\n",
            "\t Val. Loss: 1.259 |  Val. PPL:   3.521\n",
            "Epoch: 14 | Time: 0m 33s\n",
            "\tTrain Loss: 1.187 | Train PPL:   3.277\n",
            "\t Val. Loss: 1.253 |  Val. PPL:   3.502\n",
            "Epoch: 15 | Time: 0m 33s\n",
            "\tTrain Loss: 1.148 | Train PPL:   3.153\n",
            "\t Val. Loss: 1.233 |  Val. PPL:   3.430\n",
            "Epoch: 16 | Time: 0m 33s\n",
            "\tTrain Loss: 1.110 | Train PPL:   3.035\n",
            "\t Val. Loss: 1.213 |  Val. PPL:   3.362\n",
            "Epoch: 17 | Time: 0m 33s\n",
            "\tTrain Loss: 1.077 | Train PPL:   2.935\n",
            "\t Val. Loss: 1.208 |  Val. PPL:   3.347\n",
            "Epoch: 18 | Time: 0m 34s\n",
            "\tTrain Loss: 1.044 | Train PPL:   2.841\n",
            "\t Val. Loss: 1.208 |  Val. PPL:   3.346\n",
            "Epoch: 19 | Time: 0m 33s\n",
            "\tTrain Loss: 1.011 | Train PPL:   2.749\n",
            "\t Val. Loss: 1.184 |  Val. PPL:   3.267\n",
            "Epoch: 20 | Time: 0m 33s\n",
            "\tTrain Loss: 0.981 | Train PPL:   2.667\n",
            "\t Val. Loss: 1.181 |  Val. PPL:   3.257\n",
            "Epoch: 21 | Time: 0m 33s\n",
            "\tTrain Loss: 0.956 | Train PPL:   2.603\n",
            "\t Val. Loss: 1.199 |  Val. PPL:   3.317\n",
            "Epoch: 22 | Time: 0m 33s\n",
            "\tTrain Loss: 0.932 | Train PPL:   2.539\n",
            "\t Val. Loss: 1.166 |  Val. PPL:   3.208\n",
            "Epoch: 23 | Time: 0m 33s\n",
            "\tTrain Loss: 0.904 | Train PPL:   2.469\n",
            "\t Val. Loss: 1.168 |  Val. PPL:   3.217\n",
            "Epoch: 24 | Time: 0m 33s\n",
            "\tTrain Loss: 0.885 | Train PPL:   2.424\n",
            "\t Val. Loss: 1.156 |  Val. PPL:   3.177\n",
            "Epoch: 25 | Time: 0m 33s\n",
            "\tTrain Loss: 0.860 | Train PPL:   2.363\n",
            "\t Val. Loss: 1.147 |  Val. PPL:   3.149\n",
            "Epoch: 26 | Time: 0m 33s\n",
            "\tTrain Loss: 0.843 | Train PPL:   2.324\n",
            "\t Val. Loss: 1.143 |  Val. PPL:   3.135\n",
            "Epoch: 27 | Time: 0m 33s\n",
            "\tTrain Loss: 0.822 | Train PPL:   2.276\n",
            "\t Val. Loss: 1.145 |  Val. PPL:   3.143\n",
            "Epoch: 28 | Time: 0m 33s\n",
            "\tTrain Loss: 0.804 | Train PPL:   2.233\n",
            "\t Val. Loss: 1.158 |  Val. PPL:   3.183\n",
            "Epoch: 29 | Time: 0m 33s\n",
            "\tTrain Loss: 0.791 | Train PPL:   2.206\n",
            "\t Val. Loss: 1.136 |  Val. PPL:   3.114\n",
            "Epoch: 30 | Time: 0m 33s\n",
            "\tTrain Loss: 0.770 | Train PPL:   2.159\n",
            "\t Val. Loss: 1.139 |  Val. PPL:   3.123\n",
            "Epoch: 31 | Time: 0m 33s\n",
            "\tTrain Loss: 0.757 | Train PPL:   2.133\n",
            "\t Val. Loss: 1.142 |  Val. PPL:   3.132\n",
            "Epoch: 32 | Time: 0m 33s\n",
            "\tTrain Loss: 0.742 | Train PPL:   2.099\n",
            "\t Val. Loss: 1.136 |  Val. PPL:   3.116\n",
            "Epoch: 33 | Time: 0m 34s\n",
            "\tTrain Loss: 0.727 | Train PPL:   2.069\n",
            "\t Val. Loss: 1.136 |  Val. PPL:   3.114\n",
            "Epoch: 34 | Time: 0m 33s\n",
            "\tTrain Loss: 0.716 | Train PPL:   2.045\n",
            "\t Val. Loss: 1.138 |  Val. PPL:   3.121\n",
            "Epoch: 35 | Time: 0m 33s\n",
            "\tTrain Loss: 0.702 | Train PPL:   2.017\n",
            "\t Val. Loss: 1.130 |  Val. PPL:   3.097\n",
            "Epoch: 36 | Time: 0m 34s\n",
            "\tTrain Loss: 0.689 | Train PPL:   1.992\n",
            "\t Val. Loss: 1.142 |  Val. PPL:   3.133\n",
            "Epoch: 37 | Time: 0m 33s\n",
            "\tTrain Loss: 0.674 | Train PPL:   1.963\n",
            "\t Val. Loss: 1.147 |  Val. PPL:   3.150\n",
            "Epoch: 38 | Time: 0m 33s\n",
            "\tTrain Loss: 0.664 | Train PPL:   1.943\n",
            "\t Val. Loss: 1.150 |  Val. PPL:   3.158\n",
            "Epoch: 39 | Time: 0m 33s\n",
            "\tTrain Loss: 0.652 | Train PPL:   1.920\n",
            "\t Val. Loss: 1.133 |  Val. PPL:   3.104\n",
            "Epoch: 40 | Time: 0m 33s\n",
            "\tTrain Loss: 0.646 | Train PPL:   1.908\n",
            "\t Val. Loss: 1.126 |  Val. PPL:   3.084\n",
            "Epoch: 41 | Time: 0m 33s\n",
            "\tTrain Loss: 0.628 | Train PPL:   1.875\n",
            "\t Val. Loss: 1.140 |  Val. PPL:   3.128\n",
            "Epoch: 42 | Time: 0m 33s\n",
            "\tTrain Loss: 0.618 | Train PPL:   1.856\n",
            "\t Val. Loss: 1.137 |  Val. PPL:   3.116\n",
            "Epoch: 43 | Time: 0m 33s\n",
            "\tTrain Loss: 0.612 | Train PPL:   1.844\n",
            "\t Val. Loss: 1.137 |  Val. PPL:   3.118\n",
            "Epoch: 44 | Time: 0m 33s\n",
            "\tTrain Loss: 0.602 | Train PPL:   1.826\n",
            "\t Val. Loss: 1.147 |  Val. PPL:   3.149\n",
            "Epoch: 45 | Time: 0m 33s\n",
            "\tTrain Loss: 0.594 | Train PPL:   1.811\n",
            "\t Val. Loss: 1.152 |  Val. PPL:   3.166\n",
            "Epoch: 46 | Time: 0m 33s\n",
            "\tTrain Loss: 0.586 | Train PPL:   1.796\n",
            "\t Val. Loss: 1.147 |  Val. PPL:   3.148\n",
            "Epoch: 47 | Time: 0m 33s\n",
            "\tTrain Loss: 0.575 | Train PPL:   1.778\n",
            "\t Val. Loss: 1.148 |  Val. PPL:   3.151\n",
            "Epoch: 48 | Time: 0m 34s\n",
            "\tTrain Loss: 0.571 | Train PPL:   1.769\n",
            "\t Val. Loss: 1.145 |  Val. PPL:   3.144\n",
            "Epoch: 49 | Time: 0m 34s\n",
            "\tTrain Loss: 0.564 | Train PPL:   1.757\n",
            "\t Val. Loss: 1.152 |  Val. PPL:   3.164\n",
            "Epoch: 50 | Time: 0m 33s\n",
            "\tTrain Loss: 0.554 | Train PPL:   1.740\n",
            "\t Val. Loss: 1.164 |  Val. PPL:   3.204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jv6X9jjhqyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a52841-eebf-4bc7-b175-aa78c2db739b"
      },
      "source": [
        "model.load_state_dict(torch.load('tut6m-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.126 | Test PPL:   3.084 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIH21K6CiW4w"
      },
      "source": [
        "def encode_inputs(input,vocab):\n",
        "\n",
        "  tokenized_input = [tok.text.lower() for tok in spacy_en.tokenizer(input)]\n",
        "  tokenized_input = ['<sos>'] + tokenized_input +['<eos>']\n",
        "\n",
        "  numericalized_input = [vocab[i] for i in tokenized_input]\n",
        "\n",
        "  tensor_input = torch.LongTensor([numericalized_input])\n",
        "  \n",
        "  return tensor_input"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poWw6B5HifhZ"
      },
      "source": [
        "def decode_outputs(output,vocab):\n",
        "  predicted_token = output.argmax(-1)\n",
        "  return vocab[predicted_token.item()], predicted_token"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfy9RI4VigVT",
        "outputId": "fea2eccc-c34f-48e1-9dc8-4008a26667a6"
      },
      "source": [
        "print(\" Enter q or quit to exit.\")\n",
        "\n",
        "answer_max_len = 3000\n",
        "stoi = SRC.vocab.stoi\n",
        "itos = TRG.vocab.itos\n",
        "\n",
        "while(True):\n",
        "\n",
        "  input_ = input(\"Enter the Question:\")\n",
        "\n",
        "  if input_=='q' or input_=='Q' or input_=='Quit' or input_=='QUIT' or input_=='quit':\n",
        "    break\n",
        "\n",
        "  src = encode_inputs(input_,stoi).to(device)\n",
        "  src_mask = model.make_src_mask(src)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    enc_src = model.encoder(src,src_mask)\n",
        "  \n",
        "  trg = '<sos>'\n",
        "  trg_indexes = [stoi[trg]]\n",
        "\n",
        "  decoder_outputs = []\n",
        "  for i in range(answer_max_len):\n",
        "    trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "    trg_mask = model.make_trg_mask(trg_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      decoder_output,_ = model.decoder(trg_tensor,enc_src,trg_mask,src_mask)\n",
        "\n",
        "    pred_token = decoder_output.argmax(2)[:,-1].item()\n",
        "\n",
        "    if pred_token == TRG.vocab.stoi[TRG.eos_token]:\n",
        "      break\n",
        "    decoder_outputs.append(itos[pred_token])\n",
        "    trg_indexes.append(pred_token)\n",
        "\n",
        "    \n",
        "  print(\"Answer ----->:\")\n",
        "  print(\" \"+\" \".join(decoder_outputs))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Enter q or quit to exit.\n",
            "Enter the Question:Write a program to print the sum of squares of first n natural numbers\n",
            "Answer ----->:\n",
            " n = 7 \n",
            " <unk> = 0 \n",
            " for i in range ( 1 , n + 1 ) : \n",
            "      <unk> += i ** 2 \n",
            " print ( <unk> ) \n",
            "Enter the Question:Program to multiply two numbers\n",
            "Answer ----->:\n",
            " num1 = <unk> \n",
            " num2 = <unk> \n",
            " num2 = num1 * num2 \n",
            " print ( f ' P r o d u c t :   { p r o d u c t } ' ) \n",
            "Enter the Question:Program to add first n natural numbers\n",
            "Answer ----->:\n",
            " \n",
            " n = 7 \n",
            " sum1 = 0 \n",
            " while ( n > 0 ) : \n",
            "      sum1 += n \n",
            " n -= 1 \n",
            " print ( \" T h e   s u m   o f   n u m b e r s   i s t   n   n a l   n u m b e r s   i s   :   \" , sum1 ) \n",
            "Enter the Question:Program to find the sum of first n natural numbers\n",
            "Answer ----->:\n",
            " \n",
            " n = 7 \n",
            " sum1 = 0 \n",
            " while ( n > 0 ) : \n",
            "      sum1 += n \n",
            " n -= 1 \n",
            " print ( \" T h e   s u m   o f   n u m b e r s   f   n a t u r s   n   n u r s   i s   n   n   n   n a t u r s   :   \" , sum1 ) \n",
            "Enter the Question:Python program to find the product of n natural numbers\n",
            "Answer ----->:\n",
            " \n",
            " def <unk> ( n ) : \n",
            "     a = 1 \n",
            " b = 0 \n",
            " while ( n > 0 ) : \n",
            "         a += 1 \n",
            " b = n \n",
            " return a \n",
            "Enter the Question:Python program to find lcm\n",
            "Answer ----->:\n",
            " def <unk> ( x , y ) : \n",
            "     if x > y : \n",
            "         greater = x \n",
            " else : \n",
            "         greater = y \n",
            " \n",
            " \n",
            " while ( True ) : \n",
            "         if ( ( ( greater % x == 0 ) and ( greater % y == 0 ) ) ) : \n",
            "             lcm = greater \n",
            " break \n",
            " greater += 1 \n",
            " return lcm \n",
            " \n",
            " num1 = 54 \n",
            " num2 = 24 \n",
            " \n",
            " print ( \" T h e   L . C . C .   i s \" , <unk> ( num1 , num2 ) ) \n",
            "Enter the Question:Q\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}